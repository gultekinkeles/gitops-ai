{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorBoard in Workbenches\n",
    "\n",
    "Run and open TensorBoard to monitor the training process.\n",
    "\n",
    "### 1. Import the required libraries and packages.\n",
    "\n",
    "You can safely ignore the TensorFlow import warnings.\n",
    "TensorFlow typically produces these warnings on CPU-only environments where the use of accelerators, such as GPUs or certain CPU instruction sets, is limited or not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train, test, and validation subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/diabetes.csv')\n",
    "\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(f\"Number of samples in training set: {X_train.shape[0]}\")\n",
    "print(f\"Number of samples in test set: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Create and train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model.\n",
    "Use `accuracy` as the metric to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed for reproducible results\n",
    "tf.random.set_seed(10)\n",
    "tf.keras.utils.set_random_seed(10)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input((8,)),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the logging callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_dir = \"logs/training/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "logging_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model.\n",
    "Use `validation_data` to validate the model after each epoch.\n",
    "\n",
    "TensorFlow reports the value of the loss function and the `accuracy` metric for both the training and the validation subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[logging_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run TensorBoard\n",
    "\n",
    "Load the `tensorboard` notebook extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the `TENSORBOARD_PROXY_URL` environment variable to access TensorBoard from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TENSORBOARD_PROXY_URL\"] = os.getenv(\"NB_PREFIX\") + \"/proxy/6006/\"\n",
    "\n",
    "print(\"TensorBoard URL:\", os.environ[\"TENSORBOARD_PROXY_URL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the TensorBoard server.\n",
    "\n",
    "TensorBoard plots accuracy and loss for each epoch, for both the training and validation subsets.\n",
    "\n",
    "Note that, as the training progresses, the loss value decreases and the accuracy of the model increases.\n",
    "\n",
    "The fact that the validation subset accuracy remains close to the training accuracy means that the model is generalizing well on samples not seen during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
